{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12 entries, 0 to 11\n",
      "Data columns (total 12 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        12 non-null     int64 \n",
      " 1   Alt       12 non-null     object\n",
      " 2   Bar       12 non-null     object\n",
      " 3   Fri       12 non-null     object\n",
      " 4   Hun       12 non-null     object\n",
      " 5   Pat       10 non-null     object\n",
      " 6   Price     12 non-null     object\n",
      " 7   Rain      12 non-null     object\n",
      " 8   Res       12 non-null     object\n",
      " 9   Type      12 non-null     object\n",
      " 10  Est       12 non-null     object\n",
      " 11  WillWait  12 non-null     object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 1.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('Restaurant.csv')\n",
    "\n",
    "print (train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  Alt  Bar  Fri  Hun   Pat Price Rain  Res     Type     Est WillWait\n",
      "0   1  Yes   No   No  Yes  Some   $$$   No  Yes   French    0-10      Yes\n",
      "1   2  Yes   No   No  Yes  Full     $   No   No     Thai   30-60       No\n",
      "2   3   No  Yes   No   No  Some     $   No   No   Burger    0-10      Yes\n",
      "3   4  Yes   No  Yes  Yes  Full     $  Yes   No     Thai   10-30      Yes\n",
      "4   5  Yes   No  Yes   No  Full   $$$   No  Yes   French     >60       No\n",
      "5   6   No  Yes   No  Yes  Some    $$  Yes  Yes  Italian    0-10      Yes\n",
      "6   7   No  Yes   No   No   NaN     $  Yes   No   Burger    0-10       No\n",
      "7   8   No   No   No  Yes  Some    $$  Yes  Yes     Thai    0-10      Yes\n",
      "8   9   No  Yes  Yes   No  Full     $  Yes   No   Burger     >60       No\n",
      "9  10  Yes  Yes  Yes  Yes  Full   $$$   No  Yes  Italian   10-30       No\n"
     ]
    }
   ],
   "source": [
    "print(train.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'No', 'No', 'No', 'No', 'No', 'Yes', 'Yes', 'Yes', 'Yes',\n",
       "       'Yes', 'Yes'], dtype=object)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nptest = np.array(train[\"WillWait\"])\n",
    "nptest.sort()\n",
    "nptest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "YesNo_Mapping = {\n",
    "    \"Yes\": 1,\n",
    "    \"No\": 0,\n",
    "}\n",
    "\n",
    "train[\"Alt\"] = train[\"Alt\"].replace(YesNo_Mapping)\n",
    "train[\"Bar\"] = train[\"Bar\"].replace(YesNo_Mapping)\n",
    "train[\"Fri\"] = train[\"Fri\"].replace(YesNo_Mapping)\n",
    "train[\"Hun\"] = train[\"Hun\"].replace(YesNo_Mapping)\n",
    "train[\"Rain\"] = train[\"Rain\"].replace(YesNo_Mapping)\n",
    "train[\"Res\"] = train[\"Res\"].replace(YesNo_Mapping)\n",
    "train[\"WillWait\"] = train[\"WillWait\"].replace(YesNo_Mapping)\n",
    "\n",
    "Pat_Mapping = {\n",
    "    \"None\": 0,\n",
    "    \"Some\": 0.5,\n",
    "    \"Full\": 1,\n",
    "}\n",
    "\n",
    "train[\"Pat\"] = train[\"Pat\"].replace(Pat_Mapping)\n",
    "\n",
    "Price_Mapping = {\n",
    "    \"$\": 1,\n",
    "    \"$$\": 2,\n",
    "    \"$$$\": 3,\n",
    "}\n",
    "train[\"Price\"] = train[\"Price\"].replace(Price_Mapping)\n",
    "\n",
    "Type_Mapping = {\n",
    "    \"French\": 1,\n",
    "    \"Thai\": 2,\n",
    "    \"Burger\": 3,\n",
    "    \"Italian\": 4,\n",
    "}\n",
    "train[\"Type\"] = train[\"Type\"].replace(Type_Mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Type  WillWait\n",
      "0     1       0.5\n",
      "1     2       0.5\n",
      "2     3       0.5\n",
      "3     4       0.5\n"
     ]
    }
   ],
   "source": [
    "# print(train[[\"Type\", \"WillWait\"]].groupby([\"Type\"], as_index=False).mean())\n",
    "GroupedByType = train[[\"Type\", \"WillWait\"]].groupby([\"Type\"], as_index=False).mean()\n",
    "\n",
    "print(GroupedByType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pat  WillWait\n",
      "0  0.5  1.000000\n",
      "1  1.0  0.333333\n"
     ]
    }
   ],
   "source": [
    "GroupedByPat = train[[\"Pat\", \"WillWait\"]].groupby([\"Pat\"], as_index=False).mean()\n",
    "\n",
    "print(GroupedByPat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id  Alt  Bar  Fri  Hun  Pat  Price  Rain  Res  Type     Est  WillWait\n",
      "0    1    1    0    0    1  0.5      3     0    1     1    0-10         1\n",
      "1    2    1    0    0    1  1.0      1     0    0     2   30-60         0\n",
      "2    3    0    1    0    0  0.5      1     0    0     3    0-10         1\n",
      "3    4    1    0    1    1  1.0      1     1    0     2   10-30         1\n",
      "4    5    1    0    1    0  1.0      3     0    1     1     >60         0\n",
      "5    6    0    1    0    1  0.5      2     1    1     4    0-10         1\n",
      "6    7    0    1    0    0  NaN      1     1    0     3    0-10         0\n",
      "7    8    0    0    0    1  0.5      2     1    1     2    0-10         1\n",
      "8    9    0    1    1    0  1.0      1     1    0     3     >60         0\n",
      "9   10    1    1    1    1  1.0      3     0    1     4   10-30         0\n",
      "10  11    0    0    0    0  NaN      1     0    0     2    0-10         0\n",
      "11  12    1    1    1    1  1.0      1     0    0     3   30-60         1\n"
     ]
    }
   ],
   "source": [
    "print (train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(labels):\n",
    "    label_counts = np.bincount(labels)\n",
    "    label_probs = label_counts / len(labels)\n",
    "    entropy = -np.sum(label_probs * np.log2(label_probs + 1e-10))  # Add small value to avoid log(0)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gini_index(labels):\n",
    "    label_counts = np.bincount(labels)\n",
    "    label_probs = label_counts / len(labels)\n",
    "    gini_index = 1 - np.sum(label_probs ** 2)\n",
    "    return gini_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most common value in the target attribute of the given examples\n",
    "# examples: A numpy arr containing the examples\n",
    "\n",
    "# from collections import Counter\n",
    "\n",
    "def PLURALITY_VALUE(examples):\n",
    "    # classes = examples[:, -1]\n",
    "    # counts = Counter(classes)\n",
    "    # return counts.most_common(1)[0][0]\n",
    "    return np.argmax(np.bincount(examples[:, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_attribute_index (attribute, examples):\n",
    "    column_names = examples[0]\n",
    "    index = np.where(column_names == attribute)[0]\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selects the best attribute to use for splitting the data based on entropy\n",
    "# attributes: A set containing the attributes to choose from\n",
    "# examples: A NumPy array containing the examples\n",
    "\n",
    "def select_best_attribute_entropy (attributes, examples):\n",
    "    best_attribute = None\n",
    "    # best_entropy = float('inf')\n",
    "    min_entropy = np.inf\n",
    "    \n",
    "    for attribute in attributes:\n",
    "        # examples = np.array(examples)\n",
    "        # attribute_values = np.unique(examples[:, attribute])\n",
    "        # attribute_entropy = 0\n",
    "        \n",
    "        # for value in attribute_values:\n",
    "        #     value_examples = examples[examples[:, attribute] == value]\n",
    "        #     value_prob = len(value_examples) / len(examples)\n",
    "        #     value_entropy = calculate_entropy(value_examples[:, -1])\n",
    "            \n",
    "        #     attribute_entropy += value_prob * value_entropy\n",
    "        \n",
    "        # if attribute_entropy < best_entropy:\n",
    "        #     best_entropy = attribute_entropy\n",
    "        #     best_attribute = attribute\n",
    "        entropy = entropy_help(examples[:, find_attribute_index(attribute, examples)])\n",
    "        if entropy < min_entropy:\n",
    "            best_attribute = attribute\n",
    "            min_entropy = entropy\n",
    "    \n",
    "    return best_attribute\n",
    "\n",
    "\n",
    "# Calculates the entropy of the given examples.\n",
    "# examples: A NumPy array containing the examples\n",
    "def entropy_help(examples):\n",
    "    unique_values, counts = np.unique(examples, return_counts=True)\n",
    "    probabilities = counts / len(examples)\n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_attribute_GiniIndex (attributes, examples):\n",
    "    best_attribute = None\n",
    "    best_gini_index = float('inf')\n",
    "    \n",
    "    for attribute in attributes:\n",
    "        # examples = np.array(examples)\n",
    "        attribute_values = np.unique(examples[:, find_attribute_index(attribute, examples)])\n",
    "        attribute_gini_index = 0\n",
    "        \n",
    "        for value in attribute_values:\n",
    "            value_examples = examples[examples[:, attribute] == value]\n",
    "            value_prob = len(value_examples) / len(examples)\n",
    "            value_gini_index = calculate_gini_index(value_examples[:, -1])\n",
    "            \n",
    "            attribute_gini_index += value_prob * value_gini_index\n",
    "        \n",
    "        if attribute_gini_index < best_gini_index:\n",
    "            best_gini_index = attribute_gini_index\n",
    "            best_attribute = attribute\n",
    "    \n",
    "    return best_attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learns a decision tree from the given examples and attributes\n",
    "# examples: A numpy arr containing the dataset\n",
    "# attributes: A set containing the attributes\n",
    "# parent_examples: A numpy arr containing the parent examples\n",
    "# returns: A decision tree as a py dictionary\n",
    "\n",
    "def LEARN_DECISION_TREE (examples, attributes, parent_examples):\n",
    "    if len(examples) == 0:\n",
    "        return PLURALITY_VALUE(parent_examples)\n",
    "    \n",
    "    elif np.all(examples[:, -1] == examples[0, -1]):\n",
    "        return examples[0, -1]\n",
    "    \n",
    "    elif len(attributes) == 0:\n",
    "        return PLURALITY_VALUE(examples)\n",
    "    \n",
    "    else:\n",
    "        # A = select_best_attribute_entropy(attributes, examples)\n",
    "        A = select_best_attribute_GiniIndex(attributes, examples)\n",
    "        # examples_slice = np.array(examples[:, A])\n",
    "        A_index = find_attribute_index(A, examples)\n",
    "        attribute_values = np.unique(examples[:,A_index])\n",
    "        tree = {A: {}}\n",
    "        for value in np.unique(examples[:, A_index]):\n",
    "            exs = examples[examples[:, A] == value]\n",
    "            subtree = LEARN_DECISION_TREE(exs, attributes - {A}, examples)\n",
    "            tree[A][value] = subtree\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Est': {}}\n"
     ]
    }
   ],
   "source": [
    "train_data = np.array(train.head(10))\n",
    "attributes = {'Alt', 'Bar', 'Fri', 'Hun', 'Pat', 'Price', 'Rain', 'Res', 'Type', 'Est'}\n",
    "DT = LEARN_DECISION_TREE(train_data, attributes, np.array([]))\n",
    "print (DT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
