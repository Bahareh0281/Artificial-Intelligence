{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTxIaI2IYdhI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, Concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to the directory containing the digit images\n",
        "image_directory = \"/content/drive/MyDrive/ANN/train\""
      ],
      "metadata": {
        "id": "HsVzf9S7TCSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the image size for resizing\n",
        "image_size = (28, 28)"
      ],
      "metadata": {
        "id": "B-Ai08jeTCmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store the images and labels\n",
        "images = []\n",
        "labels = []"
      ],
      "metadata": {
        "id": "mzBtPuN1TDyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the images\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(image_directory, image_file)\n",
        "    image = Image.open(image_path).convert(\"L\")  # Convert to grayscale\n",
        "    image = image.resize(image_size)\n",
        "    image_array = np.array(image) / 255.0  # Normalize pixel values\n",
        "    images.append(image_array)\n",
        "\n",
        "    # Extract the label from the image file name\n",
        "    label = int(image_file.split(\"_\")[0])\n",
        "    labels.append(label)\n",
        "\n",
        "# Convert the images and labels to NumPy arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "OqAmRQovTE5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Expand dimensions for CNN input\n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "X_val = np.expand_dims(X_val, axis=-1)\n",
        "\n",
        "# Encode the labels using one-hot encoding\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_val = to_categorical(y_val, num_classes=10)"
      ],
      "metadata": {
        "id": "wdd81VIUTIXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of sub-networks (one for each digit)\n",
        "num_subnetworks = 10"
      ],
      "metadata": {
        "id": "bP3dut9OTKnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input layer\n",
        "input_layer = Input(shape=(image_size[0], image_size[1], 1))\n",
        "\n",
        "# Define the list of sub-networks\n",
        "subnetworks = []"
      ],
      "metadata": {
        "id": "-5G-0sjCTMg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the sub-networks\n",
        "for i in range(num_subnetworks):\n",
        "    # Convolutional layers\n",
        "    conv1 = Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(input_layer)\n",
        "    maxpool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(maxpool1)\n",
        "    maxpool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    flatten = Flatten()(maxpool2)\n",
        "\n",
        "    # Fully connected layers\n",
        "    dense1 = Dense(64, activation=\"relu\")(flatten)\n",
        "    output_layer = Dense(1, activation=\"sigmoid\")(dense1)\n",
        "    subnetworks.append(Model(inputs=input_layer, outputs=output_layer))"
      ],
      "metadata": {
        "id": "2WrOBB0CTNse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate the outputs of all sub-networks\n",
        "concatenated_outputs = Concatenate()(subnetworks)\n",
        "\n",
        "# Define the final prediction layer\n",
        "prediction_layer = Dense(num_subnetworks, activation=\"softmax\")(concatenated_outputs)\n",
        "\n",
        "# Create the Group-connected MLP model\n",
        "model = Model(inputs=input_layer, outputs=prediction_layer)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=32, epochs=10)\n",
        "\n",
        "# Evaluate the model on a separate test set if available\n",
        "\n",
        "# Make predictions on new test images\n",
        "# test_images = ... (preprocess the test images as done for training images)\n",
        "# test_images = np.expand_dims(test_images, axis=-1)\n",
        "# predictions = model.predict(test_images)\n",
        "# predicted_digits = np.argmax(predictions, axis=1)\n",
        "# print(predicted_digits)"
      ],
      "metadata": {
        "id": "s0zPrzDnTRbQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}