{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "klQW_soKqWIb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import skimage.io\n",
        "from skimage.io import imread\n",
        "from skimage.util import random_noise\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
        "from skimage.transform import resize\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the directory for the non-noisy images\n",
        "non_noisy_directory = \"/content/drive/MyDrive/ANN/images/train\"\n",
        "\n",
        "# Specify the directory for saving the noisy images\n",
        "noisy_directory = \"/content/drive/MyDrive/ANN/images/noisy\""
      ],
      "metadata": {
        "id": "ettOjLp5qeCG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the type and parameters of the noise\n",
        "noise_type = 'gaussian'\n",
        "variance = 0.01"
      ],
      "metadata": {
        "id": "Qz5tvXEGr6I5"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over the files in the non-noisy directory\n",
        "for filename in os.listdir(non_noisy_directory):\n",
        "    # Check if the file name matches the desired pattern\n",
        "    if filename.endswith('.jpg'):\n",
        "        file_path_non_noisy = os.path.join(non_noisy_directory, filename)\n",
        "        # Read the non-noisy image\n",
        "        non_noisy_image = imread(file_path_non_noisy)\n",
        "        # Generate the noisy image\n",
        "        noisy_image = random_noise(non_noisy_image, mode=noise_type, var=variance)\n",
        "        # Save the noisy image\n",
        "        noisy_filename = 'noisy_' + filename\n",
        "        noisy_file_path = os.path.join(noisy_directory, noisy_filename)\n",
        "        skimage.io.imsave(noisy_file_path, (noisy_image * 255).astype(np.uint8))"
      ],
      "metadata": {
        "id": "0L5fV1tOr-3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize empty lists for noisy images and non-noisy images\n",
        "noisy_images = []\n",
        "non_noisy_images = []"
      ],
      "metadata": {
        "id": "uUdphaqaqloZ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over the files in the noisy directory\n",
        "for noisy_filename in os.listdir(noisy_directory):\n",
        "    # Check if the file name matches the desired pattern\n",
        "    if noisy_filename.startswith('noisy_'):\n",
        "        # Extract the common identifier from the noisy file name\n",
        "        common_identifier = noisy_filename.split('noisy_')[1]\n",
        "        # Construct the corresponding non-noisy file name\n",
        "        non_noisy_filename = common_identifier\n",
        "        # Construct the file paths for the noisy and non-noisy images\n",
        "        file_path_noisy = os.path.join(noisy_directory, noisy_filename)\n",
        "        file_path_non_noisy = os.path.join(non_noisy_directory, non_noisy_filename)\n",
        "        # Read the noisy image\n",
        "        noisy_image = imread(file_path_noisy)\n",
        "        # Read the corresponding non-noisy image\n",
        "        non_noisy_image = imread(file_path_non_noisy)\n",
        "        # Append the images to the respective lists\n",
        "        noisy_images.append(noisy_image)\n",
        "        non_noisy_images.append(non_noisy_image)"
      ],
      "metadata": {
        "id": "4ujy9sIQqnZ8"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resize the images to the desired shape\n",
        "resized_noisy_images = []\n",
        "resized_non_noisy_images = []\n",
        "desired_shape = (32, 32)\n",
        "for noisy_image, non_noisy_image in zip(noisy_images, non_noisy_images):\n",
        "    resized_noisy_image = resize(noisy_image, desired_shape, mode='reflect', anti_aliasing=True)\n",
        "    resized_non_noisy_image = resize(non_noisy_image, desired_shape, mode='reflect', anti_aliasing=True)\n",
        "    resized_noisy_images.append(resized_noisy_image)\n",
        "    resized_non_noisy_images.append(resized_non_noisy_image)"
      ],
      "metadata": {
        "id": "ZY47fUFf4jyc"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the resized images to numpy arrays\n",
        "noisy_images = np.array(resized_noisy_images)\n",
        "non_noisy_images = np.array(resized_non_noisy_images)"
      ],
      "metadata": {
        "id": "HM5y4WnpqoDP"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the pixel values to the range [0, 1]\n",
        "noisy_images = noisy_images / 255.0\n",
        "non_noisy_images = non_noisy_images / 255.0"
      ],
      "metadata": {
        "id": "hm40eTu-qq1o"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(noisy_images, non_noisy_images, test_size=0.25)"
      ],
      "metadata": {
        "id": "OC7wLWgTqr2v"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the input data to include the channel dimension\n",
        "X_train = np.reshape(X_train, (*X_train.shape, 1))\n",
        "X_test = np.reshape(X_test, (*X_test.shape, 1))"
      ],
      "metadata": {
        "id": "CGilGO8x5THY"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the architecture of the denoising ANN\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(32, 32, 3)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "RUfDCNcpqtmk"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "metadata": {
        "id": "2pLohjo3quLp"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 928
        },
        "id": "tiwFHtDMqvqy",
        "outputId": "99749545-05ed-40b4-bd18-fce4cc1b1a46"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-80ef000548ed>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1126, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 280, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_4' (type Sequential).\n    \n    Input 0 of layer \"dense_20\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (None, 32, 32, 1)\n    \n    Call arguments received by layer 'sequential_4' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 32, 32, 1), dtype=float32)\n      • training=True\n      • mask=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate denoised images\n",
        "denoised_images = model.predict(noisy_images)"
      ],
      "metadata": {
        "id": "lf2gcfIGqyDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a random index from the test set\n",
        "index = np.random.randint(len(X_test))\n",
        "\n",
        "# Get the noisy and original images at the selected index\n",
        "noisy_image = X_test[index]\n",
        "original_image = y_test[index]\n",
        "\n",
        "# Display the noisy and original images side by side\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axes[0].imshow(noisy_image)\n",
        "axes[0].set_title('Noisy Image')\n",
        "axes[1].imshow(original_image)\n",
        "axes[1].set_title('Original Image')\n",
        "plt.show()\n",
        "\n",
        "# Calculate and display the accuracy metrics\n",
        "denoised_image = denoised_images[index]\n",
        "psnr = peak_signal_noise_ratio(original_image, denoised_image)\n",
        "ssim = structural_similarity(original_image, denoised_image, multichannel=True)\n",
        "\n",
        "print(f\"Peak Signal-to-Noise Ratio (PSNR): {psnr:.2f} dB\")\n",
        "print(f\"Structural Similarity Index (SSIM): {ssim:.4f}\")"
      ],
      "metadata": {
        "id": "abZWeQGT49XQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}