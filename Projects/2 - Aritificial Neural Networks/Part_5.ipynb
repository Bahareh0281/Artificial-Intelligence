{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QTxIaI2IYdhI"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'PIL'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32md:\\Bahareh\\7\\Files\\Artificial Intelligence\\Git\\Artificial-Intelligence\\Projects\\2 - Aritificial Neural Networks\\Part_5.ipynb Cell 1\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Bahareh/7/Files/Artificial%20Intelligence/Git/Artificial-Intelligence/Projects/2%20-%20Aritificial%20Neural%20Networks/Part_5.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Bahareh/7/Files/Artificial%20Intelligence/Git/Artificial-Intelligence/Projects/2%20-%20Aritificial%20Neural%20Networks/Part_5.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Bahareh/7/Files/Artificial%20Intelligence/Git/Artificial-Intelligence/Projects/2%20-%20Aritificial%20Neural%20Networks/Part_5.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m Image\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Bahareh/7/Files/Artificial%20Intelligence/Git/Artificial-Intelligence/Projects/2%20-%20Aritificial%20Neural%20Networks/Part_5.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Bahareh/7/Files/Artificial%20Intelligence/Git/Artificial-Intelligence/Projects/2%20-%20Aritificial%20Neural%20Networks/Part_5.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'PIL'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, Concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsVzf9S7TCSN"
      },
      "outputs": [],
      "source": [
        "# Set the path to the directory containing the digit images\n",
        "image_directory = \"train\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-Ai08jeTCmP"
      },
      "outputs": [],
      "source": [
        "# Define the image size for resizing\n",
        "image_size = (28, 28)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzBtPuN1TDyg"
      },
      "outputs": [],
      "source": [
        "# Initialize lists to store the images and labels\n",
        "images = []\n",
        "labels = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqAmRQovTE5u"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess the images\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(image_directory, image_file)\n",
        "    image = Image.open(image_path).convert(\"L\")  # Convert to grayscale\n",
        "    image = image.resize(image_size)\n",
        "    image_array = np.array(image) / 255.0  # Normalize pixel values\n",
        "    images.append(image_array)\n",
        "\n",
        "    # Extract the label from the image file name\n",
        "    label = int(image_file.split(\"_\")[0])\n",
        "    labels.append(label)\n",
        "\n",
        "# Convert the images and labels to NumPy arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdd81VIUTIXB"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Expand dimensions for CNN input\n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "X_val = np.expand_dims(X_val, axis=-1)\n",
        "\n",
        "# Encode the labels using one-hot encoding\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_val = to_categorical(y_val, num_classes=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bP3dut9OTKnN"
      },
      "outputs": [],
      "source": [
        "# Define the number of sub-networks (one for each digit)\n",
        "num_subnetworks = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5G-0sjCTMg1"
      },
      "outputs": [],
      "source": [
        "# Define the input layer\n",
        "input_layer = Input(shape=(image_size[0], image_size[1], 1))\n",
        "\n",
        "# Define the list of sub-networks\n",
        "subnetworks = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WrOBB0CTNse"
      },
      "outputs": [],
      "source": [
        "# Create the sub-networks\n",
        "for i in range(num_subnetworks):\n",
        "    # Convolutional layers\n",
        "    conv1 = Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(input_layer)\n",
        "    maxpool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(maxpool1)\n",
        "    maxpool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    flatten = Flatten()(maxpool2)\n",
        "\n",
        "    # Fully connected layers\n",
        "    dense1 = Dense(64, activation=\"relu\")(flatten)\n",
        "    output_layer = Dense(1, activation=\"sigmoid\")(dense1)\n",
        "    subnetworks.append(Model(inputs=input_layer, outputs=output_layer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0zPrzDnTRbQ"
      },
      "outputs": [],
      "source": [
        "# Concatenate the outputs of all sub-networks\n",
        "concatenated_outputs = Concatenate()(subnetworks)\n",
        "\n",
        "# Define the final prediction layer\n",
        "prediction_layer = Dense(num_subnetworks, activation=\"softmax\")(concatenated_outputs)\n",
        "\n",
        "# Create the Group-connected MLP model\n",
        "model = Model(inputs=input_layer, outputs=prediction_layer)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=32, epochs=10)\n",
        "\n",
        "# Evaluate the model on a separate test set if available\n",
        "\n",
        "# Make predictions on new test images\n",
        "# test_images = ... (preprocess the test images as done for training images)\n",
        "# test_images = np.expand_dims(test_images, axis=-1)\n",
        "# predictions = model.predict(test_images)\n",
        "# predicted_digits = np.argmax(predictions, axis=1)\n",
        "# print(predicted_digits)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
